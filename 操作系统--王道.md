[TOC]

# 操作系统基础

## 操作系统概念：

- 系统资源的管理者
    - 处理机cpu管理
    - 存储器管理
    - 文件管理
    - IO设备管理
- 向上层提供方便易用的服务
    - 提供给用户
        - GUI：图形化用户接口
        - 联机命令接口：交互式命令接口，如命令行
        - 脱机命令接口：批处理命令接口，如.bat文件
    - 提供给应用程序
        - 程序接口：在程序中进行系统调用来间接使用程序接口
- 是最接近硬件的一层软件

## 操作系统特征

- 并发：宏观上同时发生，微观上是交替发生的，而并行是指同时发生；单核CPU同一时刻只能执行一个程序，各个程序只能并发执行，多核CPU同一时刻可以同时执行多个程序，多个程序可以并行地执行。即使对于4核CPU来说，只要有4个以上的程序需要“同时”运行，那么并发行对于操作系统来说就是必不可少的。
- 共享：系统中的资源可供内存中多个并发执行的进程共同使用。
    - 互斥共享方式：系统中某些资源，虽然可以提供给多个进程使用，当一个时间段内只允许一个进程访问该资源，比如摄像头资源。
    - 系统中的某些资源，允许一个时间段内由多个进程“同时”对它们进行访问（一般是宏观上的同时，交替访问资源，即分时共享），比如硬盘资源访问。但有些资源是允许微观上同时访问使用的，比如扬声器这个声音输出设备可以同时播放两种音频。
- 虚拟：把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上对应物是用户感受到的。虚拟存储器技术和虚拟处理器技术。
- 异步：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。

## 操作系统历史

- 手工操作阶段：用户独占全机、人机速度矛盾导致资源利用率极低
- 单道批处理系统：脱机输入输出，由监督程序负责控制作业的输入和输出，CPU有大量时间等待IO
- 多道批处理系统：在计算第一个作业的同时输入第二个作业，没有人机交互功能，无法进行程序调试
- 分时操作系统：计算机以时间片为单位轮流为各个用户/作业服务
- 实时操作系统：可以优先响应一些紧急任务，并在严格时限内处理完事件
- 网络操作系统
- 分布式操作系统

## 操作系统运行机制

两种程序：

- 应用程序：普通程序员写的程序，只能使用“非特权指令”
- 内核程序：实现操作系统的程序，可能会包含一些”特权指令“，如内存清零指令

两种状态：

- 内核态：也叫核心态或管态，处于内核态时，运行的是内核程序，可以执行特权指令
- 用户态：也叫目态，处于用户态时，运行的是应用程序，只能执行非特权指令
- CPU如何判断指令类型：CPU总有一个寄存器叫做程序状态字寄存器PSW，其中有一个二进制位使用01来分别表示用户态和内核态

状态的切换：

- 内核态->用户态：执行一条特权指令--修改PSW的标识位为“用户态”，这个动作意味着操作系统将让出CPU使用权
- 用户态->内核态：由“中断”触发，硬件自动完成完态过程，触发中断信号意味着操作系统将强行夺回CPU的使用权。

## 中断和异常

中断：让操作系统内核夺回CPU使用权的唯一途径

- 内中断：也称之为异常或例外，与当前执行的指令有关，中断信号来自CPU内部
    - 陷入、陷阱trap：有时应用程序想请求操作系统内核的服务，此时会执行一条特殊的指令--陷入指令，该指令会引发一个内部中断信号。“系统调用”通过陷入指令完成
    - 故障fault：由错误条件引起，可能被内核程序修复，内核程序修复故障后会将CPU使用权还给应用程序，如缺页故障。
    - 终止abort：致命错误引起，内核程序无法修复，会终止该应用程序，如
        - 试图在用户态下执行特权指令
        - 执行除法指令发现除数为0
- 外中断：也称为中断，与当前执行的指令无关，中断信号来自CPU内外部
    - 时钟中断：由时钟部件发来的中断信号，时间片用完了
    - IO中断：打印机打印完成后会向CPU发出中断

中断机制的基本原理：不同的中断信号，需要使用不同的中断处理程序来处理。CPU检测到中断信号后，会根据中断信号的类型去查询“中断向量表”，以此来找到相应的中断处理程序这内存中的存放位置。

## 系统调用

系统调用和库函数区别：程序员可以直接使用汇编语言进行系统调用，也可以使用高级语言的库函数来间接完成系统调用。因为有些库函数种封装了系统调用以隐藏细节防病使用。

为什么系统调用是必须的：例如两个同学同时打印论文，如果两个进程可以随意的、并发的共享打印机资源，打印出的文件将会混淆。解决方法就是操作系统内核对共享资源进行统一的管理，并向上提供系统调用，用户进程想要使用打印机这种共享资源，只能通过系统调用向操作系统内核发出请求。内核会对各个请求进行协调处理，这样就解决了冲突。

系统调用按功能分类：设备管理、文件管理、进程控制、进程通信、内存管理

系统调用过程：应用程序在进行系统调用时，会将系统调用类型如fork放入寄存器，还会将其他参数放入寄存器，然后执行陷入去执行相应的中断处理程序。一个封装了系统调用的库函数的执行流程如下：

1. 前期处理相关指令
2. 传参指令：将系统带哦用需要的参数放入某些通用寄存器
3. 陷入指令/trap指令/访管指令：引发内中断，CPU进入核心态
4. 在进入核心态完成相应的中断处理程序，随后返回到用户态
5. 后续处理相关指令

## 操作系统体系结构

操作系统组成部分：

- 内核：
    - 微内核：时钟管理、中断处理、原语
    - 大内核：时钟管理、中断处理、原语 + 进程管理、存储器管理、设备管理等。
- 非内核功能：如GUI，Ubuntu、CentOS的开发团队主要是实现了非内核功能

![image-20230512033021617](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305120330658.png)

其他操作系统结构：

- 分层结构：高层调用低层，便于调试验证、扩充维护，但无法确定层之间清晰的边界，且效率低下
- 模块化：内核=主模块+可加载模块，支持动态添加新的模块（如添加驱动程序），各个模块可以相互直接调用，当模块之间相互依赖难以调试验证
- 外核：内核负责进程调度、进程通信，外核负责为用户进程分配未经抽象的硬件资源，并且由外核保证资源使用安全，减少了虚拟硬件资源的“映射层”提升了效率，降低了系统的一致性。

## 操作系统的引导

![image-20230512034516448](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305120345491.png)

## 虚拟机

![image-20230512035239104](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305120352150.png)

# 进程管理

## 进程概念

程序：静态的，存放在磁盘里面的可执行文件，就是一系列的指令集合。

进程：动态的，程序的一次执行过程，并使用唯一的PID进行标识。进程实体=PCB+程序段+数据段。进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。

PCB：进程控制块，存储管理进程时需要使用到的信息，包括

- 进程描述信息：PID和UID
- 进程控制和管理信息：CPU、磁盘、网络流量使用情况统计；进程当前状态等
- 资源分配清单：正在使用哪些文件、内存区域、I/O设备
- 处理机相关信息：PSW、PC等寄存器的值

## 进程的状态和转换

创建态、就绪态、运行态、阻塞态、终止态

![image-20230514130756105](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305141307159.png)

进程不能由阻塞态直接转换为运行态，也不能直接由就绪态转换为阻塞态。

进程的组织

- 链式方式：使用队列
- 索引方式：索引表表项指向PCB

## 进程控制

原语：原语的执行具有“原子性”，执行必须一气呵成，不允许被中断。可以使用“关中断”和“开中断”这两个特权指令实现原子性。

进程的创建：

- 创建原语
    - 申请空白PCB
    - 为新进程分配所有资源
    - 初始化PCB
    - 将PCB插入就绪队列
- 引起进程创建的事件：用户登录、作业调度、提供服务、应用请求

进程的终止：

- 撤销原语
    - 从PCB集合中找到终止程序的PCB
    - 若进程正在执行，立刻剥夺CPU，将CPU分配给其他进程
    - 终止其所有子进程
    - 将该进程拥有的所有资源归还给父进程或者操作系统
    - 删除PCB
- 引起进程终止的事件：正常结束、异常结束、外界干预

进程的阻塞：

- 阻塞原语
    - 找到要阻塞的进程对应的PCB
    - 保护进程运行现场，将PCB的状态信息设置为阻塞态，暂时停止进程运行
    - 将PCB插入相应事件的等待队列
- 事件：等待系统分配某种资源、等待相互合作的进程完成工作

进程的唤醒：

- 唤醒原语
    - 在等待队列中找到PCB
    - 将PCB从等待队列移除，设置进程为就绪态
    - 将PCB插入就绪队列等待调度
- 事件：等待的事件发生了，需要和阻塞事件对应

进程的切换：

- 切换原语
    - 运行环境信息存入PCB
    - PCB移入相应队列
    - 选择另一个进程执行，并更新其PCB
    - 根据新的PCB恢复新进程所需的运行环境
- 事件：进程时间片到、更优先的进程到达、当前进程主动阻塞、当前进程终止

## 进程通信IPC（Inter-Process Communication）

进程间通信是指两个进程之间产生数据交互。

为什么进程通信需要操作系统支持：进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间。

通信方式：

- 共享存储
    - 基于存储区的共享：进程1通过shm_open系统调用，申请一片共享存储区，进程12分别使用mmap系统调用将共享区内存映射到进程自己的虚拟地址空间。这里需要保证各个进程对共享存储区的访问是互斥的（由通信进程自己实现互斥）。
    - 基于数据结构的共享：相当于特殊的全局变量，可以在进程间共享。
- 消息传递：进程间的数据交换以格式化的信息Message为单位，进程通过操作系统提供的“发送消息/接收消息”两个原语进行数据交换。消息头：发送进程ID、接收进程ID、消息长度等格式化信息。
    - 直接通信方式：进程Q的PCB会包括一个进程Q的消息队列，进程Q使用发送原语将消息发给进程Q的消息队列，进程Q会使用接收原语从Q的消息队列复制到进程Q的地址空间。点名道姓的消息传递。
    - 间接通信方式（信箱通信方式）：发送原语指明将消息发送到哪个信箱，而接收进程可以使用接收原语从指定信箱接收消息。
- 管道通信：从管道一头写入，另一头读出，数据流向是单向的。“管道”是一个特殊的共享文件，又名pipe文件。其实就是在内存中开辟一个大小固定的内存缓冲区，管道的访问是FIFO的，本质上是一个循环队列。共享存储的方式是随机访问的。
    - 管道只能采用半双工通信，某一时间段只能实现单向的传输，需要两个管道才能双向同时通信。
    - 各个进程要互斥地访问管道（操作系统实现）
    - 管道写满时，写进程将被阻塞，直到读进程将管道中的数据取走。
    - 管道读空时，读进程将阻塞，直到写进程往管道中写入数据。
    - 没写满（只要不空）也可以读
    - 没读空（只要不满）也可以写
    - 管道中数据一旦读出，就彻底消失，因此多个进程读同一个管道时，可能会错乱。解决方案有两种：
        - 一个管道允许多个写进程，一个读进程
        - 允许有多个写进程，多个读进程，当系统会让各个读进程轮流从管道中读取数据。


## 线程

传统的进程是程序执行流的最小单位。但有的进程需要同时做很多事，所以引入了线程来增加并发度。引入线程后，线程成了程序执行流的最小单位，可以理解为“轻量级进程”。引入线程后，进程只作为除了CPU意外的系统资源的分配单元。

引入线程带来的变化：

- 资源分配调度
    - 传统进程机制中，进程是资源分配、调度的基本单位。
    - 引入线程后，进程是资源分配的基本单位，线程是调度的基本单位。
- 并发行
    - 传统进程机制中，只能进程间并发
    - 引入线程后，线程间也能并发，提高了并发性
- 系统开销
    - 传统的进程间并发，需要切换进程的运行环境，系统开销很大
    - 线程间并发后，如果是同一进程内的线程切换，则不需要切换进程环境，系统开销小
    - 引入线程后，并发所带来的系统开销减小

线程的属性：

- 线程是处理机调度的单位
- 多CPU机器中，各个线程可以占用不同的CPU
- 每个线程都有一个线程ID、线程控制块TCB
- 线程也有就绪、阻塞、运行三种基本状态
- 线程几乎不拥有系统资源
- 同一进程的不同线程间共享进程的资源
- 由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预
- 同一进程中的线程切换，会引起进程切换
- 切换同进程中的线程，系统开销很小
- 切换进程，系统开销很大

## 用户级线程/核心级线程

用户级线程：由线程库实现，很多编程语言提供了强大的线程库，可以实现线程的创建、销毁、调度等功能。本质上用户级线程其实就是一段代码逻辑，一个很弱智的“线程库”例子如下：

```c++
int main() {
		int i = 0;
		while(true) {
				if (i == 0) {// 处理视频聊天}
				if (i == 1) {// 处理文字聊天}
				if (i == 2) {// 处理文件传输}
		}
		i = （i + 1） % 3；
}
```

线程的管理工作由用户程序完成，且切换不需要CPU变态，操作系统意识不到这种线程的存在。一旦某个线程阻塞，整个进程都会被阻塞，并且多个线程无法在多核处理机下并行运行。

内核级线程：由操作系统管理，且切换时需要CPU变态，操作系统会为 每个内核级线程建立相应的TCB，通过TCB对线程进行管理。当一个线程阻塞后，别的线程还可以继续执行，并发性强，且多个线程在多核处理机下可以并行运行。当一个进程会占用多个内核级线程，线程切换由操作系统完成，需要切换到核心态，线程管理成本高开销大。

## 多线程模型

- 一对一模型：一个用户级线程对应一个内核级线程
    - 优点：一个线程阻塞后，别的线程还可以继续执行，并发能力强
    - 缺点：线程切换由操作系统内核完成，需要切换到核心态，因此线程切换成本高、开销大
- 多对一模型：多个用户级线程映射到一个内核级线程，且一个进程只被分配到一个内核级线程
    - 优点：用户级线程的切换在用户空间内即可完成，不需要切换到核心态，线程管理的系统开销小、效率高
    - 缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高，多个线程不可在多核处理机上并行运行
- 多对多模型：n用户级线程映射到m个内核级线程，每个用户对应m个内核级线程。很好的一种方式。

## 线程状态转换

![image-20230517103618699](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305171036313.png)

![image-20230517103907427](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305171039488.png)

## 调度

调度：确定某种规则来决定处理任务的顺序。

调度的三个层次：

- 高级调度（作业调度）：按一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。每个作业只调入一次，调出一次。作业调入时会建立PCB，调出时才撤销PCB。
- 低级调度（进程/处理机调度）：按照某种策略从就绪队列中选取一个进程，将处理机分配给它。进程调度的频率很高，一般是几十毫秒一次。
- 中级调度（内存调度）：内存不够时，可将某些进程的数据调到外存，等内存空闲或者进程需要运行时再重新调入内存。暂时调到外存等待的进程状态为挂起状态，被挂起的进程PCB会被组织成挂起队列。中级调度就是按照某种策略决定将哪个处于挂起状态的进程重新调入内存。

![image-20230517105117447](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305171051514.png)

## 进程调度

需要进行进程调度和切换的情况：

- 当前运行的进程主动放弃处理机
    - 正常终止
    - 异常而终止
    - 主动请求阻塞
- 当前运行的进程被动放弃处理机
    - 时间片用完
    - 更紧急的事情处理
    - 高优先级进程进入就绪队列

不能进行进程调度和切换的情况：

- 处理中断的过程中
- 进程在操作系统内核程序临界区
- 原子操作

![image-20230517110221380](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305171102454.png)

进程调度方式：

- 非剥夺调度方式（非抢占方式）：早期
- 剥夺调度方式（抢占方式）

## 调度程序/调度器和闲逛进程

调度器决定：

- 让谁运行--调度算法
- 运行多久--时间片大小

调度器的调度对象是内核级线程。

闲逛进程：调度程序永远的备胎，没有其他就绪进程时，运行闲逛进程idle

## 调度算法评价指标

- CPU利用率--甘特图
- 系统吞吐量：单位时间内完成作业的数量
- （平均）周转时间：从作业被提交给系统到作业完成这段时间间隔
- （平均）带权周转时间：周转时间 / 作业实际运行时间>=1
- （平均）等待时间：作业/进程处于等待处理机状态时间之和，在等待I/O完成期间属于被服务期间，不计入等待时间
- 响应时间：从用户提交请求到首次产生响应所用的时间

## 调度算法

### 批处理系统：

- 先来先服务FCFS

    - 按照就绪队列顺序进行服务

    - 非抢占

    - 优点：公平

    - 缺点：后面的短作业用户体验很差

    - 不会导致饥饿

- 短作业优先SJF/短进程优先SPF

    - 最短的作业/进程优先得到服务

    - SJF和SPF是非抢占式的算法

    - 也有抢占式的版本--最短剩余时间优先算法--SRTN：每当有进程加入就绪队列改变时就需要调度

    - 优点：最短的平均等待时间、平均周转时间

    - 缺点：不公平，可能会饥饿

    - 饿死

- 高响应比优先

    - 综合考虑进程/作业的等待时间和要求服务的时间
        $$
        响应比 = \frac{等待时间 + 要求服务时间}{要求服务时间}
        $$

    - 非抢占

    - 不会导致饥饿

### 交互式系统：

- 时间片轮转调度算法RR
    - 按照进程到达顺序，轮流让进程执行一个时间片
    - 用于进程调度而不是作业调度
    - 抢占式算法，由时钟装置发出时钟中断
    - 时间片太大时，退化为先来先服务
    - 时间片太大会增大进程响应时间，进程切换成本也很高，一般设置切换进程开销占比不超过1%
    - 不会导致饥饿
- 优先级调度算法
    - 调度时选择优先级最高的作业/进程
    - 作业/进程调度，甚至用于I/O调度
    - 非抢占式，主动放弃处理机发生调度
    - 抢占式版本：在就绪队列发生改变时检查是否会发生抢占
    - 静态优先级/动态优先级
    - 可能会导致饥饿
- 多级反馈队列调度算法
    - 抢占式算法：在k级队列运行过程中，若更上级的队列中进入了新的进程，则会抢占处理机
    - 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
    - 新进程到达时进入第一级队列，按照FCFS原则排队等待被分配时间片，若时间片用完进程没结束，则进入下一级队列队尾
    - 只有第k级队列为空时，才会为k+1级对头的进程分配时间片
    - 会导致饥饿

### 多级队列调度算法

![image-20230517135349656](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305171353812.png)

## 进程同步&进程互斥

进程同步就是为了解决进程异步带来的问题，进程互斥是指进程访问临界资源必须要互斥，临界区是指访问临界资源的那段代码。互斥访问需要遵循空闲让进、忙则等待、有限等待、 的原则。

```c++
// 进入区
// 临界区
// 退出区
// 剩余区
```

## 进程互斥的软件实现方法

### 单标志法

两个进程在访问完临界区后会把使用临界区的权限转交给另外一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予。这种方法违反了”空闲让进“原则，例如进程0将访问权让给进程1之后，如果1一直不访问临界区，这会一直霸占访问权。

```c
int turn = 0; // turn表示当前允许进入临界区的进程号

// 对于P0进程
while (turn != 0);
critical section;
turn = 1;
remainder section;
```

### 双标志先检查法

设置一个布尔型数组flag[]，数组中各个元素用来标记各进程想要进入临界区的意愿。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身标记设置为true，之后开始访问临界区。但是可能会违反”忙则等待“原则，可能会有两个进程同时进入临界区。

```c
bool flag[2];
flag[0] = flase;
flag[1] = false;

// 对于P0进程
while (flag[1]);
flag[0] = true;
critical section;
flag[0] = false;
remainder section;
```

### 双标志后检查法

先“上锁”后“检查”，但是违反了“空闲让进”和“有限等待”原则。

```c
// 对于P0进程
flag[0] = true;
while (flag[1]);
critical section;
flag[0] = false;
remainder section;
```

### Peterson算法

结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试“孔融让梨”。未遵循“让权等待”原则：即使无法进入临界区，也会一直占用CPU资源。

```c
int turn = 0; // turn表示当前允许进入临界区的进程号，表达谦让
bool flag[2]; // 表达意愿

// 对于P0进程
flag[0] = true;
turn = 1;
while(flag[1] && turn = 1);
critical section;
flag[0] = false;
remainder section;
```

## 进程互斥的硬件实现方法

### 中断屏蔽方法

利用“开/关中断指令”实现（和原语的实现思想类似，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况。

```c
// 关中断
// 临界区
// 开中断
```

不适用于多处理机；只适用于操作系统内核进程，不适用于用户进程。

###  Test&Set指令

简称TS指令，也称为TestAndLock指令或者TSL指令。

它是用硬件实现的，执行的过程中不允许被中断，只能一气呵成。实现逻辑如下：

```c
// lock表示当前临界区是否被加锁
// true表示已加锁，false表示未加锁
bool TestAndSet (bool *lock) {
  bool old;
  old = *lock;
  *lock = true;
  return old;
}

// 以下是使用TSL指令实现互斥的算法逻辑
while (TestAndSet (&lock)); // 上锁并检查
// 临界区代码段；
lock = false;
// 剩余区代码段；
```

不符合让权等待，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致忙等。

### Swap指令

也称为Exchange或者XCHG指令。

它是用硬件实现的，执行的过程中不允许被中断，只能一气呵成。实现逻辑如下：

```c
// swap指令的作用是交换两个变量的值
Swap （bool *a, bool *b) {
  bool temp;
  temp = *a;
  *a = *b;
  *b = temp;
}

// 以下是使用Swap指令实现互斥的算法逻辑
// lock表示当前临界区是否被加锁
bool old = true;
while (old == true)
  Swap (&lock, &old);
// 临界区代码段；
lock = false;
// 剩余区代码段；
```

逻辑上基本等同于TSL指令。

### 锁

解决临界区最简单的工具就是互斥锁，一个进程在进入临界区时应该获得锁，在退出临界区时释放锁。每个互斥锁有一个布尔变量available，表示锁是否可用，进程在acqiure()锁时会不会成功取决于锁此时是否可用。当一个进程试图获得不可用的锁时，会被阻塞，直到锁被释放。

其中acquire()和release()必须是原子操作，因此互斥锁通常使用硬件机制实现。

互斥锁主要缺点是忙等待，当有一个进程在临界区中，任何其他进程在进入临界区时必须连续循环调用acquire()。多个进程共享同一CPU时，就浪费了CPU周期。因此互斥锁通常用于多处理器系统，一个线程在一个处理器上等待，不影响其他线程的执行。

需要连续循环忙等的互斥锁都可以称为自旋锁，如TSL指令、swap指令、单标志法。

## 信号量机制

进程互斥软件实现方式：

- 单标志法
- 双标志先检查法：进入区的“检查”，“上锁”操作无法一气呵成，导致两个进程有可能同时进入临界区。
- 双标志后检查法
- Peterson算法

进程互斥的硬件实现方式：

- 中断屏蔽
- TS/TSL指令
- Swap/XCHG指令

上面的所有解决方案都无法实现“让权等待”（需要等待临界区资源时下处理机等待），所以需要引入信号量机制。

用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥和同步。

一对原语：wait(S)原语和signal(S)原语，其实就是两个函数，也可以写成P(S)、V(S)

### 整型信号量

可以用一个整型信号量来表示系统中某种资源的数量。

```c
int S = 1;

void wait(int S) {
	while (S <= 0);
	S = S-1;
}

void signal (int S) {
	S = S+1;
}

// 进程P0
wait(S);
//临界区
signal(S);
```

不满足“让权等待”原则。

### 记录型信号量

定义如下：

```c
typedef struct {
  int value; // 初值为某种资源数量
  struct process *L; // 等待队列
} semaphore；

void wait (semaphore S) {
  S.value--;
  if(S.value < 0) {
    block(S.L); // 如果剩余资源数不够，使用block原语使进程从运行态进入阻塞态，并把进程挂到信号量S的等待队列中。
  }
}

void signal (semaphore S) {
  S.value++;
  if(S.value <= 0) {
    wakeup(S.L); // 释放资源后，若还有别的进程在等待这种资源，则使用wakeup原语唤醒等待队列中的一个进程，该进程从阻塞态变为就绪态。
  }
}
```

### 使用信号量机制实现进程同步、前驱关系

进程同步：让各个并发进程按照要求有序推进。例如：

```c
// 设置同步信号量S=0
semaphore S = 0;

P1(){
  code1;
  code2;
  V(S);	// 释放资源
  code3;
}

P1(){
  P(S); // 申请资源
  code4;
  code5;
  code6;
}
// 只有在执行完V(S)操作后才能执行P(S)，先释放V才能申请P，实现了进程之间的同步。
```

每一对前驱关系都是一个进程同步问题，需要设置一个同步信号量。

### 生产者消费者问题

系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者每次从缓冲区中取出一个产品并使用，缓冲区大小为n

两组同步关系：只有缓冲区没满，生产者才能生产；只有缓冲区没空，消费者才能消费。

各个进程还需要互斥访问缓冲区。

```c
semaphore mutex = 1;	// 互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n;	// 同步信号量，表示空闲缓冲区的数量
semaphore full = 0;		// 同步信号量，表示产品的数量

producer (){
  while(1){
    // 生产
    P(empty);	// 实现同步
    P(mutex);	// 实现互斥
    // 产品放入缓冲区
    V(mutex);	// 实现互斥
    V(full);	// 实现同步
  }
}

producer (){
  while(1){
    P(full);	// 实现同步
    P(mutex);	// 实现互斥
    // 从缓冲区取出产品
    V(mutex);	// 实现互斥
    V(empty);	// 实现同步
    // 使用产品
  }
}

//P操作不能交换顺序，V操作可以。
```

### 多生产者多消费者问题

桌子上一个盘子，每次只能向其中放入一个水果，爸爸专向盘子中放苹果，而妈妈则是橘子，儿子专吃橘子，女儿专吃苹果。 

互斥关系：对盘子的访问

同步关系：

- 父亲放苹果->女儿取苹果
- 母亲放橘子->儿子取橘子
- 盘子为空->父母放水果

一共需要1个互斥信号量，3个同步信号量。但是因为这里缓冲区为1，所以可以发现同步信号量已经实现了4个进程对盘子的互斥访问，所以互斥信号量是冗余的。

### 吸烟者问题

假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉，但是要卷起并抽掉一根烟需要三种材料：烟草、纸、胶水。三个抽烟者中分别拥有三种材料之一。供应者无限提供三种材料，且每次将两种材料放到桌子上，拥有剩余材料的抽烟者将卷一根烟并抽掉它，并给供应者一个信号告诉完成了，供应者会放下一组材料到桌子上，过程一直重复（让三个抽烟者轮流抽烟）。

单生产者多消费者材料。

互斥关系：需要互斥访问，但桌子的缓冲区为1，可以不设置。

同步关系：

- 桌子上有组合1->第1个抽烟者
- 桌子上有组合2->第2个抽烟者
- 桌子上有组合3->第3个抽烟者
- 发出完成信号->供应者放下一个组合

![image-20230527154536410](https://raw.githubusercontent.com/s2drag0n/Pictures/main/image-20230527154536410.png)

### 读者写者问题

读者和写者两组并发进程，共享同一个文件。要求：

- 允许多个读者同时读
- 只允许一个写者写
- 任意写者在完成写之前不允许其他读者或写者工作
- 写者执行写前需要已有的读者和写者全部退出

互斥关系：写和写互斥、写和读互斥、读和读不互斥

设置int count = 0用来记录当前正在访问文件的读进程数量，只有第一个读进程才会对文件加锁。

### 哲学家进餐问题

![image-20230527160524963](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305271605080.png)

也可以设置仅当两根筷子都可用时才拿起筷子。

## 管程

信号量机制存在的问题：编写程序困难、易出错

管程是一种高级同步机制。有这些部分组成：

- 局部于管程的共享数据结构说明
- 对该数据结构操作的过程
- 局部于管程的数据结构初始化语句
- 管程有一个名字

基本特征：

- 局部于管程的数据只能被局部于管程的过程访问
- 一个进程只能通过调用管程内的过程才能进入管程访问共享数据

- 每次仅允许一个进程在管程内执行某个内部过程

## 死锁

在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是“死锁”。发生死锁后若无外力干涉，这些进程都无法向前推进。

死锁、饥饿、死循环的区分。

死锁产生的必要条件：

- 互斥条件：互斥的资源争抢
- 不可剥夺：持有资源后不可被剥夺
- 请求和保持：该进程至少保持了一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程已被阻塞，但是又对自己已有的资源保持不放。
- 循环等待

死锁的处理策略：预防、避免（银行家算法）、死锁的检测和解除。

### 预防死锁

破坏互斥条件：比如SPOOLing技术，操作系统使用这种技术把独占设备在逻辑上改造成共享设备。本质上是使用一个进程接管对独占设备的申请。

破坏不剥夺条件：

- 方案一：当某个进程请求新的资源不得到满足时必须释放其保持的所有资源
- 方案二：当某个进程被其他进程所占有时，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般考虑各个进程的优先级。

破坏请求和保持条件：

- 采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前不会让他投入运行，一旦投入运行，这些资源就一直归它所有且不会请求别的任何资源。
- 这种方式资源利用率很低。

破坏循环等待条件：

- 顺序资源分配法，首先给系统中的资源进行编号，规定每个进程必须按照编号递增的顺序请求资源，同类资源一次申请完。这种情况下，一个进程只有已经占有了小编号的资源时才有资格申请更大编号的资源。按此规则，已经持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而不会产生循环等待的情况。
- 不方便增加新的设备、资源实际使用顺序可能和编号递增顺序不一致、必须按照次序申请资源，用户编程麻烦。

### 避免死锁

安全序列：如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态，一定不会发生死锁。如果系统进入不安全状态就可能会发生死锁。

银行家算法：确保银行在发放现金贷款时不会发生不能满足所有客户需要的情况。

![image-20230528185421244](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305281854355.png)

### 死锁的检测和解除

死锁检测

![image-20230528185859682](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202305281858821.png)

死锁解除：

- 资源剥夺法：挂起某些进程，释放其资源
- 撤销进程法：强制撤销部分甚至全部死锁进程，并剥夺资源。
- 进程回退法：让一个或多个进程回退到足以发生死锁的地步。

如何决定对谁动手：

- 进程优先级
- 已执行时间
- 待执行时间
- 进程已经使用多少资源
- 进程是交互式还是批处理的

# 内存管理

## 内存基础

可执行文件（装入模块）装入内存的方式：

- 绝对装入：在编译时如果知道程序将放入内存的哪个位置，编译程序将产生绝对地址的目标代码，只适用于单道程序环境。
- 静态重定位（可重定位装入）：使用从0开始的逻辑地址，装入时对地址进行重定位，将逻辑地址加上分配的起始地址转换成物理地址。特点是在装入作业时必须分配其要求的全部内存空间。作业一旦进入内存，在运行时就无法移动且无法申请内存空间。
- 动态重定位（动态运行时装入）：使用从0开始的逻辑地址，装入内存时不需要做地址转换，而到了程序开始执行时才进行地址转换。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持。允许程序在内存中发生移动，且无需一次性装入即可运行。

链接的三种方式：

- 静态链接：在程序运行之前，将各目标模块以及他们所需要的库函数连接成一个完整的可执行文件，之后不再拆开。
- 装入时动态链接：将各目标模块装入内存时，边装入边链接。
- 运行时动态链接：在程序执行中需要该目标模块时，才对它进行链接。优点是便于修改和更新，便于实现对目标模块的共享。

内存管理的概念

- 内存空间的分配和回收
- 从逻辑上对内存空间进行扩充--虚拟性
- 地址转换--逻辑地址转换为物理地址
- 内存保护--保护进程在各自的内存空间
    - 在CPU中设置一堆上、下限寄存器
    - 采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）

## 内存空间的扩充

### 覆盖技术

将程序分为多个段（多个模块），常用的段常驻内存，不常用的段在需要时调入内存。

内存中分为一个“固定区”和一个“覆盖区”。需要常驻内存的段放在“固定区”，不常用的段放入“覆盖区”。

按照自身逻辑，让那些不可能被同时访问的程序段共享同一个覆盖区，当需要程序要指定这种逻辑。

### 交换技术

内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中已经具备运行条件的进程换入内存。所谓的中级调度（内存调度）就是决定将将哪个处于挂起状态的进程重新调入内存。

应该在外存（磁盘）的什么位置保存被换出的进程：通常把磁盘空间分为文件区和对换区两部分，文件区主要用于存放文件，追求存储空间的利用率，因此采用离散分配方式。而对换区空间只占磁盘空间的小部分，主要追求换入换出速度，因此采用连续分配方式。

交换发生在许多进程运行且内存吃紧的情况，比如缺页现象频繁发生时。

优先交换阻塞进程、优先级低的进程或者考虑在内存的驻留时间。（PCB会常驻内存，不会被换出。）

## 虚拟存储技术

### 基本概念

传统的存储管理：

* 连续分配：单一连续分配、固定分区分配、动态分区分配
* 非连续分配：基本分页、基本分段、基本段页

这些存储管理的问题：

* 一次性：作业必须一次性装入内存。这导致无法装入大作业，且大量作业运行时，由于内存无法容纳所有作业导致系统并发度下降。
* 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内只需要访问作业的以下部分数据即可正常运行。

虚拟存储技术：

* 基于局部性原理，可以将程序中很快会用的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。
* 在程序执行过程中，当访问的信息不在内存中时，由操作系统将所需的信息调入内存，然后继续执行。
* 如果内存空间不够，操作系统负责将内存中暂时用不到的信息换出外存。
* 虚拟内存的特点：多次性、对换性、虚拟性
* 虚拟内存的实现需要建立在离散分配的内存管理方式基础上
  * 请求分页存储管理
  * 请求分段存储管理
  * 请求段页式存储管理

### 请求分页存储管理方式

这种方式下的页表项：

* 内存块号
* 状态位：是否已经调入内存
* 访问字段：记录最近被访问几次或者记录上次访问的时间
* 修改位：页面调入内存后是否被修改过
* 外存地址

每当要访问的页面不在内存时，就会产生一个缺页中断，然后又操作系统的缺页中断处理程序处理中断。此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。 

如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项；如果内存中没有空闲块，则要将其写回外存。未修改过的页面不用写回外存。

缺页中断属于故障，所以是内中断。一条指令执行期间，可能会产生多次缺页中断。

在调入页面时需要同时修改慢表和快表。

当内存满时，需要换出页面，需要使用页面置换算法。

### 页面置换算法

最佳置换算法：每次淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，保证了最低的缺页率。 但是无法实现。

先进先出置换算法：每次淘汰的页面是最早进入内存的页面。把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。这种算法可能会导致Belady异常--当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。只有FIFO算法会导致这种异常。

最近最久未使用置换算法（LRU）：使用访问字段记录该页面自上次访问以来所经历的时间。算法性能好，但开销大。

时钟置换算法（CLOCK）：又叫最近未用算法。一种简单的实现方式是，为每个页面设置一个访问位，在将内存中的页面都通过链接指针链接成一个循环队列，当某页被访问时，其访问位置是1。当需要淘汰一个页面时，只需要检查页的访问位。如果是0就选择该页换出；如果是1，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位一次设置为0后进行第二轮扫描，这一轮扫描必然有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描。

改进型的时钟置换算法：注意到只有被淘汰的页面被修改过时，才需要写回内存。使用（访问位，修改位）表示各页面状态，修改位为0表示未被修改，访问位同上。算法规则如下。

* 第一轮扫描：从当前位置找（0，0），找不到进入第二轮（最近没访问，没修改）
* 第二轮扫描：查找第一个（0，1），且本轮将所有扫描过的帧访问位设置为0（最近没访问，但修改）
* 第三轮扫描：查找第一个（0，0）（最近访问过，但没修改）
* 第四轮扫描：查找第一个（0，1）（最近访问过，但修改）

### 页面分配策略

驻留集是指请求分页存储管理中给进程分配的物理块的集合，在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。驻留集太大，并发度低；驻留集太小，又导致缺页频繁。

驻留集有固定分配和可变分配两种分配方式。

在置换页面时有局部置换（只能置换进程自己的物理块）和全局置换（可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程）两种。

有以下三种组合方式：

* 固定分配局部置换
* 可变分配全局置换：只要缺页就会分配新的物理块（空闲物理块或者别的进程物理块）
* 可变分配局部置换：只允许置换自己的物理块，但是频繁缺页发生时，系统会为进程多分配几个物理块，直到该进程缺页率适当。

何时调入页面：

* 预调页策略：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。主要用于进程的首次调入。
* 请求调页策略：缺页时才调页

何处调入页面（外存=对换区+文件区）：

* 系统拥有足够的对换区空间时：页面的调入、调出都是在内存与对换区之间进行。在进程运行之前，需要将相关的进程的数据从文件区复制到对换区。
* 系统缺少足够的对换区空间时：凡是不会被修改的数据将直接从文件区调入，可能会被修改的部分换出时需要写回磁盘对换区。
* UNIX方式：运行进程之前所有进程相关数据全部放在文件区，故未使用过的也买你都可以从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要从对换区调入。

抖动（颠簸）现象：刚换出的页面马上又换入内存，刚换入的页面马上换出外存的现象。主要原因是进程频繁访问的页面数目高于可用的物理块数。物理块太少，抖动现象；物理块太多，并发度下降。所以提出了工作集（在某段时间间隔里，进程实际访问页面的集合）。一般来说需要保证驻留集大小不小于工作集大小。

### 内存映射文件Memory-Mapped Files

传统的文件访问方式：

1. open系统调用打开文件
2. seek系统调用移动读写指针
3. read系统调用读出
4. write系统调用写入

内存映射文件解决这种麻烦的访问方式：

1. open系统调用打开文件
2. mmap系统调用将文件映射到进程的虚拟地址空间
   * 以访问内存的方式访问文件数据
   * 文件数据的读入和写出都是由操作系统自动完成
   * 进程关闭文件时，操作系统自动将文件修改的数据写回磁盘。

多个进程可以映射同一个文件，实现共享。

## 内存空间的分配与回收

### 连续分配管理方式

单一连续分配：

- 内存被分为系统区和用户区，系统区通常位于低地址部分，用于存放操作系统相关数据；用户区用于存放用户进程相关数据。
- 内存中只能有一道用户程序，用户程序独占整个用户区空间。
- 优点是实现简单、无外部碎片、可以采用覆盖技术扩充内存。
- 缺点是只能用于单用户、单任务的操作系统且有内部碎片。

固定分区分配：

- 将整个用户空间划分为若干个固定的分区，在每个分区中只装入一道作业，这就是最早的支持多道程序的内存管理方式。可以选择分区大小相等、分区大小不等两种方式。
- 操作系统需要建立一个数据结构--分区说明表，实现各个分区的分配和回收。
- 无外部碎片、有内部碎片。

动态分区分配（可变分区分配）：

- 不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态的建立分区。
- 操作系统采用空闲分区表或者空闲分区链记录内存的使用情况。
- 动态分区分配算法：从空闲分区中选出哪一个分区分配给该作业？
- 分区的分配和回收操作如何进行？
- 有外部碎片

外部碎片，可以通过紧凑（拼凑）技术来解决。

### 动态分区分配算法

首次适应算法：

* 每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
* 需要建立空闲分区表或者空闲分区链，按照以地址递增的次序排列。

最佳适应算法：

* 空闲分区按照容量递增次序进行链接。
* 每次分配时顺序查找空闲分区，找到大小能满足要求的第一个空闲分区。
* 但是会留下很多难以利用的小碎片

最坏适应算法：

* 又称最大适应算法，为了解决最佳适应算法留下太多小碎片的问题，这种方法在每次分配内存时使用最大的连续空闲区。
* 空闲分区按照容量递减次序进行链接。
* 当有大进程到达时，可能没有内存可用。

邻近适应算法：

* 首次适应算法每次都要从链头开始查找，这会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
* 空闲分区按照地址递增顺序排列（可以排列成循环链表），每次分配内存时从上次查找结束位置开始查找。 

## 分页存储管理

### 基本分页存储管理概念

将内存地址分为一个个大小相等的分区（比如4KB），每个分区就是一个“页框”（页框=页帧==内存块=物理块=物理页面），每个页框有一个编号，即”页框号“，从0开始。

将进程的逻辑地址空间也分为与页框大小相等的一个个部分,每个部分称为一个“页”或“页面”，每个页面也有一个编号，即“页号”，也是从0开始编号。

操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框内，也就是说进程的页面与内存的页框是一一对应的。

为了能知道进程的每个页面在内存中存放的位置，操作系统需要为每个进程建立一张页表，并保存在进程PCB中。

* 一个进程对应一张页表
* 进程的每个页面对应一个页表项
* 每个页表项由页号和块号组成
* 页表记录进程页面和实际存放的内存块之间的映射关系
* 其中页号不占存储空间，相当于数组下标

> 每个页表项占多少字节......
>
> 逻辑地址到物理地址的转换：若要访问逻辑地址A
>
> 1. 确定逻辑地址A对应的页号P = 逻辑地址/页面长度
> 2. 找到P号页面在内存中的起始地址（查页表）
> 3. 确定逻辑地址A的页内偏移量 = 逻辑地址%页面长度
>
> 页面大小为2的整数次幂的好处：
>
> * 逻辑地址的拆分更为迅速，高位是页号，低位是页内偏移量
> * 物理地址的计算更加迅速，直接将查询到的内存块号和页内偏移量拼接即可得到物理地址。

### 基本地址变换机构

基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。通常会在系统中设置一个页表寄存器PTR，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的起始地址和页表的长度放在进程控制块PCB中，当进程被调度时，操作系统内核会把他们放在页表寄存器中。

1. 根据逻辑地址计算出页号、页内偏移量
2. 判断页号是否越界（页号>=页表长度表示越界）
3. 查询页表，找到页号对应的页表项，确定页面存放的内存块号
4. 用内存块号和页内偏移量得到物理地址

页式管理中地址是一维的；实际应用中，通常使一个页框恰好可以放入整数个页表项；为了方便的找到页表项，页表一般放在连续的内存块中。

### 具有快表的地址变换机构

快表，又称为联想寄存器（TLB，translation lookaside buffer），是一种访问速度比内存快很多的高速缓存，用来存放最近访问过的页表项的副本，可以加速地址变换的速度，与此对应，内存中的页表通常称为慢表。

进程切换时，快表的内容会被清空。

具有快表的地址变换过程：

1. CPU给出逻辑地址，由某个硬件算出页号、页内偏移量，将页号和快表中所有页号进行比较。
2. 如果命中，直接根据相应的快表项中的内存块号+页内偏移进行一次访存即可。
3. 如果未命中，则去访问内存中的页表，同时将页表项存入快表。得到页表项中的内存块号后，再根据偏移量进行第二次访存。

一般来说，快表的命中率可以达到90%，这是由于局部性原理。

* 时间局部性：程序中的循环
* 空间局部性：访问一个内存，后附近的内存一般也会被访问

有的系统支持快表慢表同时查询，在计算平均访存时间时需要注意。

### 两级页表

> 单级页表存在的问题
>
> 假设这样一种情况：计算机按字节寻址，支持32位的逻辑地址，采用分页存储管理，页面大小为4KB，页表项长度为4B
>
> 4KB的页面大小，所以页内地址需要有12位，所以20位表示页号，也就是最多会有1M个的页表项，所以整个页表长度最大为$2^{22}$B，共需要$2^{10}$个页框存储该页表。
>
> 1. 页表的查询方式需要保证页表在内存空间中是连续的，而1024个连续页框空间非常难得，这和页式存储管理的离散存储管理思想是违背的。
> 2. 由局部性原理可以知道，很多时候，进程在一段时间内只需要访问某几个页面就可以正常运行。因此没有必要让整个页表都常驻内存。

问题一：二级页表

可以将长长的页表进行分组，使每个内存块可以刚好放入一个分组，例如在上个例子中每连续1k个页表为一组。再将各组离散的放到各个内存块中。此外，要为离散分配的页表再建立一张页表，称为页目录表，或称为外层页表，或称顶层页表。

采用二级页表的地址变换过程为：

1. 按照地址结构将逻辑地址分为三部分：一级页号+二级页号+页内偏移量
2. 从PCB中读出页目录表起始地址，再根据一级页号查页目录表，找到二级页表在内存中的位置
3. 根据二级页号查表，找到最终想访问的内存块号
4. 结合页内偏移量得到物理地址

问题二：虚拟存储技术

可以在需要访问页面时才把页面调入内存。在页表项中增加一个标志位，用于表示该页面是否已经调入内存。若想访问的页面不在内存中，则产生缺页中断，然后将目标页面从外存调入内存。

## 分段存储管理

按照程序自身的逻辑关系将程序的地址空间划分为若干个段，每个段有一个段名，在低级语言中程序员使用段名来编程，每段从0开始编址。

在进行内存分配时，以段为单位进行分配，每个段在内存中占连续空间，但各段之间可以不相邻。编译程序会将低级语言中的段名转换为段号。逻辑地址由段号+段内地址组成。

操作系统为每个进程建立一张段映射表，简称段表：

* 每个段对应一个段表项，记录了该段的段号以及在内存中的起始地址（基址）和段的长度
* 各个段表项的长度是相同的，其中段号可以是隐含的，不占存储空间。

操作系统维护一个段表寄存器，其中记录了段表的起始地址和段表长度。

分段存储地址转换过程

1. 根据逻辑地址得到段号、段内地址
2. 判断段号是否小于段表长度，小于说明没有越界
3. 查询段表，找到对应的段表项
4. 检查段内地址是否超过了段长，超过了说明越界，否则继续执行。
5. 计算得到物理地址并访问目标内存单元

## 段页式管理方式

分页管理和分段管理的优缺点

|      | 优点                                                     | 缺点                                                         |
| ---- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 分页 | 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 | 不方便按照逻辑模块实现信息的共享和保护                       |
| 分段 | 方便按照逻辑模块实现信息的共享和保护                     | 如果段长过大，为其分配很大的连续空间会很不方便。另外段式管理会产生外部碎片。 |

* 段页式管理方式是先按照进程逻辑模块对进程进行分段，然后再对每段进行分页。
* 段页式管理的逻辑地址结构 = 段号 + 页号 + 页内偏移量
* 其中段管理对用户可见，页管理对用户不可见，所以这种方式是二维的。
* 段表中记载的不再是段起始地址和段长，而是页表长度和页表起始地址（页表存放内存块号）。
* 一个进程对应一个段表，一个段对应一个页表。

段页式管理方式地址转换过程：

1. 根据逻辑地址得到段号、页号、页内偏移量
2. 判断段号是否越界
3. 查询段表，得到该段对应的页表起始地址和页表长度
4. 检查页号是否越界
5. 查询页表，找到对应页表项
6. 计算出物理地址并访问内存单元

上述管理方式均可以使用快表加快访问速度。

# 文件管理

## 初识文件管理

文件就是一组有意义的信息/数据的集合。文件的属性有：

* 文件名：同一目录下不允许重名
* 标识符：一个系统内的各文件标识符唯一
* 文件类型
* 位置
* 大小
* 创建、修改时间等

文件内部如何组织？

* 无结构文件，也叫流式文件，如txt
* 有结构文件，也叫记录式文件，如excel，文件的逻辑结构

文件之间如何组织？

* 通过目录进行树状组织

os提供哪些功能方便用户、应用程序使用文件？

* 创建文件--create系统调用
* 读文件--read系统调用
* 写文件--write系统调用
* 删除文件--delete系统调用
* 打开、关闭文件--open、close系统调用
* 文件共享和保护

文件数据如何存放在外存上：文件的物理结构

## 文件的逻辑结构

文件的逻辑结构就是在用户看起来，文件内部的数据应该是如何组织起来的。而物理结构是指在操作系统看来，文件的数据是如何存在外存中的。同数据结构中的逻辑结构和物理结构。

无结构文件就是流式二进制，没有逻辑结构。

有结构文件由若干条记录组成，又可分为定长记录和可边变长记录两种。

### 顺序文件

文件中的记录一个接一个顺序排列，记录可以是定长或可变长的。各个记录在物理上可以是顺序存储或者是链式存储。

顺序文件又可分为串结构（记录之间顺序与关键字无关）和顺序结构（记录顺序按关键字顺序排列）。

* 链式存储：无法随机存取
* 顺序存储
  * 可变长记录：无法随机存取
  * 定长记录：可实现随机存取
    * 串结构：无法快速找到某关键字对应的记录
    * 顺序结构：可以快速找到某关键字对应的记录（如折半查找）

### 索引文件

> 需求：对于可变长记录文件，要找到第i个记录，必须先顺序查找前i-1个记录，但是很多场景下必须使用可变长记录，如何解决？

建立一张索引表以加快文件检索速度。每条记录对应一个索引表项，索引表项=索引号+长度+指针。文件中的记录则可以离散地存放。

索引表本身是定长记录的顺序文件，因此可以随机存取。可以将关键字作为索引号内容，这样就支持根据关键字快速查找。

主要用于对信息处理的及时性要求比较高的场景。

### 索引顺序文件

> 需求：对于索引文件，每个记录对应一个索引表项，浪费存储空间

给记录分组，一组记录对应一个索引表项。

## 文件目录

文件控制块：目录文件中的一条记录就是一个文件控制块（FCB），它实现了文件名和文件之间的映射，使得用户可以按名存取。FCB的有序集合称为文件目录，一个FCB就是一个文件目录项，包含了文件的基本信息（文件名、物理地址、逻辑结构、物理结构等），存取控制信息（是否可读/可写、禁止访问的用户名单等），使用信息（文件的建立时间修改时间等）。

目录操作：搜索、创建文件、删除文件、修改目录、显示目录

目录结构：

* 单级目录结构：整个系统只有一张目录表，不允许文件重名
* 两级目录结构
  * 主文件目录：记录用户名和相应用户文件目录存放位置
  * 用户目录：用户文件FCB组成
* 多级目录结构--树级目录结构
  * 绝对路径
  * 相对路径：降低了检索文件时磁盘I/O的次数。
  * 不便于实现文件的共享
* 无环图目录结构
  * 可以用不同的文件名指向相同的文件
  * 为每一个共享结点设置一个共享计数器，为0时删除文件

索引节点（FCB的改进）：除了文件名之外的文件描述信息都放到索引节点中，FCB仅保存文件名+索引节点指针，降低了检索文件时磁盘I/O的次数。

## 文件的物理结构

操作系统对磁盘进行的管理：

* 非空闲磁盘块：文件的物理结构
* 空闲磁盘块：文件存储空间

在外存中，文件的逻辑地址也被分为了一个一个的文件块，也就是逻辑地址=逻辑快号+块内地址。

### 连续分配

要求每个文件在磁盘中占有一组连续的块。

优点：

* 找到该文件对应的目录项（FCB），然后直接从FCB中可以得到相应的物理块号。
* 访问的两个磁盘间隔越远，移动磁头时间就越长，所以顺序读写很快。

缺点：

* 不方便拓展文件
* 可能无法分配足够连续磁盘块，或者产生大量磁盘碎片，可以使用紧凑来处理。

### 链接分配

隐式链接：

* FCB给出了起始块和结束块，每个磁盘块都会保存指向下一个磁盘块的指针。
* 方便扩展，无碎片
* 无法随机存取

显式链接：

* 把用于链接文件各物理块的指针显式存放在一张表中，也就是文件分配表（FAT）
* 目录项FCB中只需要记录文件的起始块号
* FAT中表项=物理块号+下一块号
* 一个磁盘只需要一张FAT
* 支持顺序访问，支持随机访问
* 不会产生外部碎片，方便扩展

### 索引分配

系统为文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块。索引表存放的磁盘称为索引块，文件数据存放的磁盘称为数据块。

需要在FCB中记录索引块是几号磁盘块。

支持随机访问，可扩展。

当一个索引表大于一个磁盘块内存时：

* 链接方案：将多个索引表进行链接
* 多级索引：各层索引表大小不能超过一个磁盘块
* 混合索引

## 文件的物理结构和逻辑结构

逻辑结构：

* 用户（文件创建者）的视角看到的样子
* 在用户看来，整个文件占用连续的逻辑地址空间
* 文件内部的信息组织完全由用户自己决定，操作系统并不关心

物理结构：

* 由操作系统决定文件采用什么物理结构存储
* 操作系统负责将逻辑地址转变为（逻辑块号，块内偏移量）的形式并实现逻辑块号到物理块号的映射。

## 文件存储空间管理

初始化：将各个文件卷划分为目录区、文件区

存储空间管理：

* 空闲表法
  * 创建一个空闲盘块表，其表项为（第一个空闲盘块号x，空闲盘块数y），其表示含义是从第x块开始的y个存储块是空闲的
  * 适用于连续分配方式
  * 回收磁盘块时注意表项的合并问题
* 空闲链表法
  * 空闲盘块链：每一个空闲块磁盘块单独作为链的单元
    * 操作系统保存着链头和链尾指针
    * 适用于离散分配的物理结构
  * 空闲盘区链：连续的空闲块组成一个空闲区，每个空闲区作为链的单元
    * 分配时，如果有大小符合要求的空闲盘区，就会直接分配
    * 如果没有，也可以将不同盘区的盘块分配给一个文件。
* 位示图法
  * 每个二进制对应一个盘块，例如0代表空闲1代表已分配，位示图一般使用连续的字来表示。可以使用（字号，位号）对应一个盘块号
  * 适用于连续和离散分配方式
* 成组链接法
  * 文件卷的目录区中专门用一个磁盘块用作“超级块”，当系统启动时需要将超级块读入内存。并且要保证内外存中的超级块数据一
  * 超级块保存下一组空闲盘块数和空闲块号，且下一组空闲盘块中的第一个块保存了下下一组空闲盘块数和空闲块号

## 文件操作

创建文件：

1. 在外存找到文件所需的空间
2. 创建目录项

删除文件

1. 根据路径找到目录项
2. 找到外存地址回收
3. 删除目录想

打开文件

1. 根据路径找到目录项，并检查用户的操作权限
2. 把目录项复制到内存中的“打开文件表”中，并将相应的表目编号返回给用户。之后用户使用打开文件表的编号来指明要操作的文件

关闭文件

1. 打开文件表删除表项
2. 回收分配给文件的内存空间等资源
3. 系统打开文件表的打开计数器-1，如果为0则删除该表项

读文件

1. 先打开文件
2. 从读指针取数据

写文件

1. 先打开文件
2. 使用写指针写入数据

## 文件共享和保护

共享：

* 基于索引结点的共享方式（硬链接）：目录中的索引结点指针同时指向索引节点（其中保存了共享计数器和文件物理地址）
* 基于符号链的共享方式 （软链接）：快捷方式

保护：

* 口令保护：用户请求访问文件时必须提供口令
* 加密保护：使用密码对文件进行加密（一种最简单的加密方式--异或）
* 访问控制：在FCB中增加一个访问控制列表ACL，该列表中记录了各个用户对该文件执行哪些操作。
  * 可以以组为单位管理用户权限

# IO设备管理

## I/O控制器

CPU无法直接控制I/O设备的机械部件，因此I/O设备需要有一个电子部件作为CPU和I/O设备机械部件之间的“中介”，用于实现CPU对设备的控制。

需要完成的功能：

* 接受和识别CPU发出的命令：控制器中设置相应的控制寄存器存放命令和参数
* 向CPU报告设备的状态：控制器中设置相应的状态寄存器，用于记录I/O设备当前的状态
* 数据交换：设置相应的数据寄存器
* 地址识别

I/O控制器由CPU与控制器的接口、I/O逻辑、控制器与设备的接口三部分组成。其中I/O逻辑负责接受和识别CPU的各种命令，并负责对设备发出命令。一个I/O控制器可能会有多个控制器与设备的接口，控制多个设备。CPU与控制器的接口实现CPU和控制器之间的通信，主要通过控制线、地址线、数据线。

一个I/O控制器的数据、状态、控制寄存器可能会有多个，且都要有相应的地址才能方便CPU进行操作。有的计算机会让这些寄存器占用内存地址的一部分，称为**内存映像I/O**，相当于内存扩展；另一些计算机则采用I/O专用地址，即**寄存器独立编址**。

## I/O控制方式

### 程序直接控制方式

![image-20230606153952405](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061539637.png)

### 中断驱动方式

![image-20230606154108959](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061541121.png)

### DMA方式

DMA方式（Direct Memory Access，直接存储器存取）主要用于块设备（如磁盘）的I/O控制，改进如下：

* 数据传送单位是块，而不再是一个字
* 数据的流向是从设备直接放入内存或者直接从内存到设备，不再需要CPU作为中转。
* 仅在传送一个或多个数据块的开始和结束时，才需要CPU干预，来指明这次要进行的操作。
* DMA控制器会根据CPU提出的要求完成数据的“读写”工作，在完成后才向CPU发出中断信号。

![image-20230606155153022](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061551112.png)

### 通道控制方式

一个通道可以控制多个I/O控制器，一个I/O控制器可以控制多个设备。

![image-20230606155513609](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061555701.png)

![image-20230606155638122](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061556213.png)

![image-20230606155708850](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061557946.png)

## I/O软件层次结构

由上至下依次为：

* 用户层软件（库函数）：实现了假脱机技术（SPOOLing技术）
* 设备独立性软件（系统调用）：I/O调度、设备保护、设备分配和回收、缓冲区管理
* 设备驱动程序：各种设备内部硬件特性不同，需要特定的驱动程序
* 中断处理程序：I/O完成时，控制器发送中断信号，系统根据中断信号类型找到相应的中断处理程序
* 硬件

## 输入输出应用程序接口&设备驱动程序接口

### 输入输出应用程序接口

![image-20230606163134248](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061631358.png)

* 阻塞I/O：应用程序发出I/O系统调用，进程需转为阻塞态等待--如字符设备接口
* 非阻塞I/O：应用程序发出I/O系统调用，系统调用可迅速返回，进程无需等待--如块设备接口

### 设备驱动程序接口

操作系统规定好设备驱动程序的接口标准，各厂商必须按照要求开发设备驱动程序。

## I/O核心子系统

### I/O调度

使用某种算法确定一个好的顺序来处理各个I/O请求。

### 设备保护

将设备看成特殊的文件，同文件保护

### 假脱机技术SPOOLing

脱机技术：也就是脱离主机的控制进行输入和输出操作。例如批处理时期使用外围控制机将数据存入磁带，再输入计算机使用。

假脱机技术：使用软件的方式模拟脱机技术。

![image-20230606164817648](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061648723.png)

共享打印机原理分析：

![image-20230606165038719](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061650806.png)

## 设备分配和回收

设备分配时应考虑的因素：

* 设备的固有属性：独占设备、共享设备、虚拟设备（SPOOLing技术实现的共享设备）
* 设备的分配算法：先来先服务、高优先级等
* 设备分配中的安全性
  * 安全分配方式：为进程分配一个设备后就将进程阻塞，I/O完成后才将进程唤醒。对于一个进程，一段时间内它只能使用一个设备且CPU和I/O设备只能串行工作。
  * 不安全分配方式：进程发出I/O请求后，系统为其分配I/O设备，进程可继续执行，之后还可以发出新的I/O请求，只有当某个I/O请求得不到满足时才将进程阻塞。CPU和I/O可以并行处理，但是有可能发生死锁。

两种分配方式：

* 静态分配：进程运行前为其分配全部资源
* 动态分配：运行中动态申请

设备分配管理中的数据结构：一个系统--多个通道--多个I/O控制器--多个I/O设备

* DCT设备控制表：设备类型、设备标识符、设备状态、指向控制器表的指针、重复执行次数或事件、设备队列的队首指针（指向等待该设备的进程PCB队列）
* COCT控制器控制表：控制器标识符、控制器状态、指向通道表的指针、队首指针、队尾指针
* CHCT通道控制表：通道标识符、通道状态、与通道连接的控制器表首址、通道队列的队首指针、通道队列的队尾指针
* SDT系统设备表：记录了系统中全部设备的情况，每个设备对应一个表目，表目内容包括设备类型、设备标识符、DCT、驱动程序入口

设备分配步骤：

1. 根据进程请求的物理设备名查找SDT
2. 根据SDT找到DCT，忙碌则将PCB挂到设备等待队列，不忙碌则将设备分配给进程
3. 根据DCT找到COCT，忙碌则将PCB挂到控制器等待队列，不忙碌则控制器分配给进程
4. 根据COCT找到CHCT，忙碌则将PCB挂到通道等待队列，不忙碌则通道分配给进程
5. 都分配成功，才能进行I/O操作
6. 改进：建立逻辑设备名到物理设备名的映射，编程时只需要提供逻辑设备名，设置逻辑设备表LUT

## 缓冲区管理

缓冲区是一个存储区域，可以有专门的硬件寄存器组成，也可以利用内存作为缓冲区。

缓冲区的作用：

* 缓和CPU与I/O设备速度不匹配的问题
* 减少对CPU的中断频率
* 解决数据颗粒度不匹配问题：例如输出进程每次生成一块数据，但是I/O设备每次只能输出一个字符
* 提高CPU和I/O设备的并发度

缓冲区策略：

* 单缓冲：假设某进程请求某种块设备读入若干块的数据，操作系统会在主存中为进程分配一个缓冲区。缓冲区非空不可冲入数据，缓冲区充满才能读出数据。
* 双缓冲
* 循环缓冲区：将多个大小相等的缓冲区链接成一个循环队列，in指针指向下一个空缓冲区，out指针指向下一个满缓冲区
* 缓冲池：缓冲区按照使用状况分为空缓冲队列、输入队列、输出队列。

![image-20230606172559293](https://raw.githubusercontent.com/s2drag0n/Pictures/main/202306061725358.png)

## 磁盘管理

### 磁盘的结构

每个盘面都有一个磁头，一个盘片可能会有两个盘面。所有盘面中相对位置相同的磁盘组成柱面。

（柱面号，盘面号，扇区号）表示一个磁盘块的地址。

磁头可以移动的叫活动头磁盘，每个磁道都有一个磁头的结构叫做固定头磁盘。

又可以分为可换盘磁盘和固定盘磁盘。

### 磁盘调度算法

一次磁盘读写需要的时间：

* 寻找时间（寻道时间）$T_s$：在读写数据之前，将磁头移动到指定磁道所花的时间，包括启动磁头臂和移动磁头到目标磁道。
* 延迟时间$T_R$：通过旋转磁盘，使得磁头定位到目标扇区所需的时间，和转速有关。
* 传输时间$T_t$：从磁盘读出或写入数据所需要的时间就是磁盘旋转使得磁头从目标扇区开始，到目标扇区结束位置所需要的时间，和转速有关。

磁盘调度算法：

* 先来先服务：按照请求到达的顺序，磁头依次移动到相应位置并访问。
* 最短寻找时间优先：优先处理与当前磁头最近的磁道请求。
* SCAN扫描算法：只有移动到最外磁道才能向内移动，只有移动到最内磁道才能向外移动。
* LOOK调度算法：在扫描算法基础上，如果在磁头移动方向上没有别的请求，则会立马改变方向。
* C-SCAN循环扫描算法：只有磁头向特定方向移动时，才处理请求，返回起点时直接快速移动。
* C-LOOK调度算法：在循环扫描算法，如果在磁头移动方向上没有别的请求，则会立马改变方向。

### 减少延迟时间的方法

磁头读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，则读入几个连续的扇区，可能需要浪费好几个磁道的旋转周期，需要很长的“延迟时间”。

采用**交替编号**的策略，让逻辑上相邻的扇区有一定的间隔。

**磁盘地址结构**的设计：为什么不使用（盘面号，柱面号，扇区号），使用（柱面号，盘面号，扇区号）。

**错位命名**：相邻盘面相对位置相同的扇区编号错位不同。和交替编号是一种优化逻辑。

### 磁盘管理

磁盘初始化：

1. 低级格式化（物理格式化），将磁盘的各个磁道划分为扇区，一个扇区通常可分为头、数据区域、尾三个部分。
2. 将磁盘分区，每个分区由相邻的若干个柱面组成。
3. 逻辑格式化，创建文件系统。

引导块：计算机开机需要执行自举程序进行初始化工作，这些自举程序存放在ROM中，但是很不方便。所以现代的计算机会将自举程序存放在磁盘的启动块上，启动块位于磁盘的固定位置。往往只是在ROM中存放很小的“自举装入程序”，开机时计算机先运行“自举装入程序”以将完整的自举程序读入内存，完成初始化。拥有启动程序的分区称为系统盘，如C盘。

坏块的管理：在文件分配表FAT中记录了坏块。复杂的磁盘会自己维护坏块链表，磁盘也会保留备用磁盘块以代替坏块，这个过程对操作系统透明。

### 固态硬盘SSD

原理：基于闪存技术，属于电可擦除。

结构：

* 闪存翻译层
* 闪存芯片组--闪存芯片0--块0--页0

固态硬盘页是存取单位，所以对应机械硬盘的一个块，也就是一个扇区。

以页为单位写入，如果这个页有内容，则必须擦除整个块才能对该页进行写入，为了保护块中其他页内容，必须将块中其他页保存在其他块中，且闪存翻译层会更改地址映射，所以固态硬盘读操作快，写操作慢。

支持随机访问，因为是电路地址访问。

固态硬盘的块擦除次数过多可能会坏，所以有磨损均衡技术：

* 静态磨损均衡：读多写少的数据放到老旧的块上。
* 动态磨损均衡：写入数据时，优先选择累计擦除次数少的新闪存块。









